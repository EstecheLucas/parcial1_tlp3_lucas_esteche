{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fee5ee9",
   "metadata": {},
   "source": [
    "# Examen Parcial n°1 2da Parte - TLP3 - Python para Ciencia de Datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999099d0",
   "metadata": {},
   "source": [
    "**A partir del datasets brindado, realizar los siguientes procedimientos:**\n",
    "\n",
    "* Importar datasets con Pandas.\n",
    "* Explorar los datos con los metodos correspondientes. \n",
    "* Limpieza de los datos (Normalización de datos).\n",
    "* Obtener estadisticas.\n",
    "* Mostrar los datos procesados con graficos utilizando la libreria Matplotlib.\n",
    "* Exportar el contenido a un archivo sqlite utilizando PANDAS.\n",
    "\n",
    "\n",
    "**Importante: Se debe documentar cada procedimiento realizado, siguiendo la siguiente estructura:**\n",
    "\n",
    "1. Celda de Markdown (Documentación)\n",
    "2. Código (Sin comentarios, se debe documentar lo sufiente solo en la celda de markdown).\n",
    "\n",
    "\n",
    "### Criterios de Evaluación:\n",
    "\n",
    "1. No esta permitido el uso de IAs durante el examen. (Desactivar Copilot o cualquier herramienta de IA para autocompletar codigo.)\n",
    "\n",
    "2. Se deben utilizar nombres de variables descriptivos y claros (Utilizar la nomeclatura correspondiente para los nombres de variables).\n",
    "\n",
    "3. Comentarios claros y concisos que expliquen el propósito de cada sección del código en una celda de markdown antes del código.\n",
    "\n",
    "4. Utilizar mensajes de commit descriptivos. (Puedes utilizar la extension CONVENTIONAL COMMIT de VS-CODE).\n",
    "\n",
    "5. Entrega en tiempo y forma (Parciales entregados fuera de hora o con commits pasados el horario de entrega quedará invalidado.)\n",
    "\n",
    "6. Todo el código desarrollado debe ser subido a un repositorio en GitHub (el nombre del repositorio de seguir la siguiente estructura: \n",
    "**parcial1_tlp3_nombre_apellido**).\n",
    "\n",
    "7. Para resolver las actividades se debe insertar casillas de codigo entre cada actividad del cuaderno de Jupyter.\n",
    "\n",
    "8. Deben trabajar con el datasets adjunto.\n",
    "\n",
    "9. Una vez finalizado el examen, los resultados deben quedar guardados debajo de cada celda (NO EJECUTAR LA OPCIÓN \"borrar todas las salidas\").\n",
    "\n",
    "**Importante:** Una vez finalizado el examen, marcar como completado en el classroom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd91f969",
   "metadata": {},
   "source": [
    "## Actividades: \n",
    "### 1. Importación del Dataset con Pandas\n",
    "\n",
    "En esta sección, se debe utilizar la librería Pandas para cargar el archivo CSV que contiene los datos de VOTACIONES en un Datasets.\n",
    "\n",
    "### 2. Exploración Inicial de los Datos\n",
    "\n",
    "A continuación, se deben emplear métodos de Pandas para obtener una visión general del dataset. \n",
    "- 2.1: Visualizar las primeras filas y ultimas.\n",
    "- 2.2: Obtener informacion del df con su metodo correspondiente.\n",
    "- 2.3: Hacer un conteo de valores nulos.\n",
    "\n",
    "### 3. Limpieza y Normalización de los Datos\n",
    "\n",
    "- 3.1. Esta etapa crucial deben aplicar la corrección de diversos errores presentes en el dataset. Se abordarán los valores faltantes (Deben aplicar los metodos que ustedes crean convenientes **(Solo 1)**, por ejemplo: Eliminación de filas, cubrir valores con media, mediana, etc.)\n",
    "- 3.2: La columna Fecha deberan pasarla al tipo datetime con su metodo correspondiente.\n",
    "- 3.3: Corregir las mayusculas en el caso de Nombre y Apellido (Si es que corresponde.)\n",
    "- 3.4: En el caso de los votos, aplicar mayusculas a cada fila.\n",
    "- 3.5 EL campo DNI debe ser del tipo INT.\n",
    "\n",
    "\n",
    "### 4. Obtención de Estadísticas Descriptivas\n",
    "\n",
    "Después de la limpieza, deben hacer lo siguiente: \n",
    "\n",
    "- 4.1: calcular nuevamente las estadísticas descriptivas para observar el impacto del proceso de limpieza en los datos numéricos.\n",
    "- 4.2: Calcular estadísticas específicas por grupo (Agrupar dos columnas).\n",
    "\n",
    "### 5. Visualización de los Datos con Matplotlib\n",
    "\n",
    "En esta sección, deben utilizar la librería Matplotlib para crear **UNA** visualización que permitan comprender mejor los datos de ventas.El grafico es a elección, puede crear **UNO** de los siguientes: histogramas, diagramas de dispersión, gráficos de barras y graficos de torta.\n",
    "\n",
    "### 6. Exportación a Archivo SQLite\n",
    "\n",
    "Finalmente, deben utilizar la funcionalidad de Pandas para guardar el DataFrame procesado en una base de datos SQLite. Deben hacer una conexión y hacer una consulta para ver si los datos fueron cargados correctamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0bed34",
   "metadata": {},
   "source": [
    "***ACTIVIDAD 1***\n",
    "Se importo las librerias necesarias y se mostró las primeras filas del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92347d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nombre apellido         dni     provincia  voto fecha_votacion\n",
      "0  pánfilo    pombo  34787190.0  buenos aires  nulo     2024-11-22\n",
      "1   albina  heredia  48336819.0      santa fe  nulo     2024-04-24\n",
      "2      NaN   solano  49179364.0       neuquen  nulo     2024-05-20\n",
      "3   salomé   barrio  43725639.0  buenos aires   NaN     05-06-2024\n",
      "4   matías  esteban  30599927.0         chaco    no     10-07-2023\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('votaciones.csv')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df77133",
   "metadata": {},
   "source": [
    "***ACTIVIDAD 2***\n",
    "\n",
    "Se mostró las primeras y ultomas filas con head y tail, se obtuvo informacion del df con su metodo correspondiente y se hizo un conteo de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e17352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        nombre apellido         dni     provincia  voto fecha_votacion\n",
      "0     pánfilo    pombo  34787190.0  buenos aires  nulo     2024-11-22\n",
      "1      albina  heredia  48336819.0      santa fe  nulo     2024-04-24\n",
      "2         NaN   solano  49179364.0       neuquen  nulo     2024-05-20\n",
      "3      salomé   barrio  43725639.0  buenos aires   NaN     05-06-2024\n",
      "4      matías  esteban  30599927.0         chaco    no     10-07-2023\n",
      "..        ...      ...         ...           ...   ...            ...\n",
      "96      carla    vidal  15161718.0      misiones  nulo     2023-09-12\n",
      "97   federico  barrios  16171819.0       neuquen    no     11-09-2023\n",
      "98      belen     vera  17181920.0       tucuman    sí     2023-09-10\n",
      "99    gustavo    gauna  18192021.0      santa fe  nulo     09-09-2023\n",
      "100     rocio    avila  19202122.0       formosa    no     08-09-2023\n",
      "\n",
      "[101 rows x 6 columns]>\n",
      "<bound method NDFrame.tail of        nombre apellido         dni     provincia  voto fecha_votacion\n",
      "0     pánfilo    pombo  34787190.0  buenos aires  nulo     2024-11-22\n",
      "1      albina  heredia  48336819.0      santa fe  nulo     2024-04-24\n",
      "2         NaN   solano  49179364.0       neuquen  nulo     2024-05-20\n",
      "3      salomé   barrio  43725639.0  buenos aires   NaN     05-06-2024\n",
      "4      matías  esteban  30599927.0         chaco    no     10-07-2023\n",
      "..        ...      ...         ...           ...   ...            ...\n",
      "96      carla    vidal  15161718.0      misiones  nulo     2023-09-12\n",
      "97   federico  barrios  16171819.0       neuquen    no     11-09-2023\n",
      "98      belen     vera  17181920.0       tucuman    sí     2023-09-10\n",
      "99    gustavo    gauna  18192021.0      santa fe  nulo     09-09-2023\n",
      "100     rocio    avila  19202122.0       formosa    no     08-09-2023\n",
      "\n",
      "[101 rows x 6 columns]>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101 entries, 0 to 100\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   nombre          91 non-null     object \n",
      " 1   apellido        94 non-null     object \n",
      " 2   dni             90 non-null     float64\n",
      " 3   provincia       95 non-null     object \n",
      " 4   voto            96 non-null     object \n",
      " 5   fecha_votacion  95 non-null     object \n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 4.9+ KB\n",
      "None\n",
      "                dni\n",
      "count  9.000000e+01\n",
      "mean   3.864910e+07\n",
      "std    2.400198e+07\n",
      "min    1.011121e+07\n",
      "25%    1.982167e+07\n",
      "50%    3.319309e+07\n",
      "75%    4.886738e+07\n",
      "max    9.900112e+07\n",
      "nombre            10\n",
      "apellido           7\n",
      "dni               11\n",
      "provincia          6\n",
      "voto               5\n",
      "fecha_votacion     6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.head)\n",
    "print(df.tail)\n",
    "print(df.info())\n",
    "\n",
    "print(df.describe())\n",
    "\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23abf179",
   "metadata": {},
   "source": [
    "***ACTIVIDAD 3***\n",
    "\n",
    "Eliminamos los valores nulos, cambiamos nombre, apellido y votos a mayuscula, convertimos dni a entero, se pudo solucionar el formato de las fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1ed772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['nombre', 'apellido', 'dni', 'provincia', 'voto', 'fecha_votacion'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df[\"nombre\"] = df[\"nombre\"].str.capitalize\n",
    "df[\"apellido\"] = df[\"apellido\"].str.capitalize\n",
    "\n",
    "df[\"voto\"] = df[\"voto\"].str.upper()\n",
    "\n",
    "\n",
    "\n",
    "df[\"dni\"] = df[\"dni\"].astype(int)\n",
    "\n",
    "df[\"fecha_votacion\"] = pd.to_datetime(df[\"fecha_votacion\"],dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7902b5",
   "metadata": {},
   "source": [
    "***ACTIVIAD 4***\n",
    "\n",
    "Se muestra las estadisticas descriptiva en general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "432c0902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadisticas generales \n",
      "       nombre apellido           dni provincia voto fecha_votacion\n",
      "count      91       94  9.000000e+01        95   96             95\n",
      "unique     90       92           NaN        12    3             91\n",
      "top     lucas     sosa           NaN   neuquen   no     23-09-2023\n",
      "freq        2        2           NaN        13   33              2\n",
      "mean      NaN      NaN  3.864910e+07       NaN  NaN            NaN\n",
      "std       NaN      NaN  2.400198e+07       NaN  NaN            NaN\n",
      "min       NaN      NaN  1.011121e+07       NaN  NaN            NaN\n",
      "25%       NaN      NaN  1.982167e+07       NaN  NaN            NaN\n",
      "50%       NaN      NaN  3.319309e+07       NaN  NaN            NaN\n",
      "75%       NaN      NaN  4.886738e+07       NaN  NaN            NaN\n",
      "max       NaN      NaN  9.900112e+07       NaN  NaN            NaN\n",
      "estadisticas de dos grupos\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001734459C8F0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Estadisticas generales \")\n",
    "print(df.describe(include=\"all\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"estadisticas de dos grupos\")\n",
    "grupo_columnas =df.groupby([\"provincia\", \"voto\"])\n",
    "\n",
    "print(grupo_columnas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ede0a",
   "metadata": {},
   "source": [
    "***ACTIVIDAD 5*** Tuve problemas con la instalación de esta libreria por lo que no la pude importar y lamentablemente no pude hacer el grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44bde3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8aa7912",
   "metadata": {},
   "source": [
    "***ACTIVIDAD 6***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6b38eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"votaciones.db\")\n",
    "\n",
    "df.to_sql(\"votaciones\",conn,\n",
    "          if_exists=\"replace\", index=False)\n",
    "\n",
    "consulta = pd.read_sql(\"SELECT * FROM votaciones\",conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3490164e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "Error binding parameter 1: type 'method' is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mProgrammingError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m conn = sqlite3.connect(\u001b[33m\"\u001b[39m\u001b[33mvotaciones.db\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvotaciones\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreplace\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m conn.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\IPF-2025\\Desktop\\examen-parcial-practico-n1\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\IPF-2025\\Desktop\\examen-parcial-practico-n1\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3087\u001b[39m, in \u001b[36mNDFrame.to_sql\u001b[39m\u001b[34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[39m\n\u001b[32m   2889\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2890\u001b[39m \u001b[33;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[32m   2891\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3083\u001b[39m \u001b[33;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[32m   3084\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m   3085\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[32m-> \u001b[39m\u001b[32m3087\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3088\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3089\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3090\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3091\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3092\u001b[39m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3093\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3094\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\IPF-2025\\Desktop\\examen-parcial-practico-n1\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:842\u001b[39m, in \u001b[36mto_sql\u001b[39m\u001b[34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    838\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m'\u001b[39m\u001b[33m argument should be either a Series or a DataFrame\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    839\u001b[39m     )\n\u001b[32m    841\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema=schema, need_transaction=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\IPF-2025\\Desktop\\examen-parcial-practico-n1\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:2851\u001b[39m, in \u001b[36mSQLiteDatabase.to_sql\u001b[39m\u001b[34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[39m\n\u001b[32m   2841\u001b[39m table = SQLiteTable(\n\u001b[32m   2842\u001b[39m     name,\n\u001b[32m   2843\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2848\u001b[39m     dtype=dtype,\n\u001b[32m   2849\u001b[39m )\n\u001b[32m   2850\u001b[39m table.create()\n\u001b[32m-> \u001b[39m\u001b[32m2851\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\IPF-2025\\Desktop\\examen-parcial-practico-n1\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:1119\u001b[39m, in \u001b[36mSQLTable.insert\u001b[39m\u001b[34m(self, chunksize, method)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1118\u001b[39m chunk_iter = \u001b[38;5;28mzip\u001b[39m(*(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[32m-> \u001b[39m\u001b[32m1119\u001b[39m num_inserted = \u001b[43mexec_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_inserted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\IPF-2025\\Desktop\\examen-parcial-practico-n1\\.venv\\Lib\\site-packages\\pandas\\io\\sql.py:2547\u001b[39m, in \u001b[36mSQLiteTable._execute_insert\u001b[39m\u001b[34m(self, conn, keys, data_iter)\u001b[39m\n\u001b[32m   2545\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_insert\u001b[39m(\u001b[38;5;28mself\u001b[39m, conn, keys, data_iter) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   2546\u001b[39m     data_list = \u001b[38;5;28mlist\u001b[39m(data_iter)\n\u001b[32m-> \u001b[39m\u001b[32m2547\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minsert_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m conn.rowcount\n",
      "\u001b[31mProgrammingError\u001b[39m: Error binding parameter 1: type 'method' is not supported"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect(\"votaciones.db\")\n",
    "\n",
    "df_votaciones.to_sql(\"votaciones\",conn, if_exists = \"replace\",index=False)\n",
    "\n",
    "consulta = pd.read_sql_query(\"SELECT + FROM votaciones LIMIT 5\", conn)\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
